services:
  postgres:
    image: postgres:17-alpine
    environment:
      POSTGRES_DB: portfolio
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d portfolio" ]
      interval: 3s
      timeout: 1s
      retries: 5
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager
    networks:
      - portfolio_network
    ports:
      - '5432:5432'

  redis:
    image: redis:8-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 3s
      timeout: 1s
      retries: 5
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network

  backend:
    image: ktenman/portfolio-be:latest
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/portfolio
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_PROFILES_ACTIVE: default
      VISION_ENABLED: "true"
      TELEGRAM_BOT_ENABLED: "true"
      VISION_BASE64_ENCODED_KEY: ${VISION_BASE64_ENCODED_KEY}
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      BUILD_HASH: ${BUILD_HASH:-local}
      BUILD_TIME: ${BUILD_TIME:-local}
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/actuator/health || exit 1" ]
      interval: 8s
      timeout: 2s
      retries: 15
    deploy:
      mode: replicated
      replicas: 1  # Run multiple instances for high availability
      update_config:
        parallelism: 1  # Update one at a time
        delay: 30s  # Wait 30s between updates
        order: start-first  # Start new ones before stopping old ones
        failure_action: rollback  # Auto rollback on failure
        monitor: 60s  # Monitor for failure for 60s after update
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2048M
    networks:
      - portfolio_network
    depends_on:
      - postgres
      - redis

  frontend:
    image: ktenman/portfolio-fe:latest
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:80 || exit 1" ]
      interval: 3s
      timeout: 1s
      retries: 5
    deploy:
      mode: replicated
      replicas: 2  # Run multiple instances for high availability
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network
    depends_on:
      - backend

  auth:
    image: ktenman/auth:latest
    environment:
      SERVER_PORT: 8083
      SPRING_REDIS_HOST: redis
      REDIRECT_URI: "https://fov.ee"
      ALLOWED_LOGINS: "ktenman"
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      ALLOWED_EMAILS: ${ALLOWED_EMAILS}
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8083/actuator/health || exit 1" ]
      interval: 6s
      timeout: 2s
      retries: 18
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network
    ports:
      - '8083:8083'
    depends_on:
      - redis

  app:
    image: caddy:2.10-alpine
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - caddy_data:/data
      - caddy_config:/config
      - type: bind
        source: /home/githubuser/Caddyfile
        target: /etc/caddy/Caddyfile
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/healthz"]
      interval: 12s
      timeout: 3s
      retries: 5
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network

  market_price_tracker:
    image: ktenman/market-price-tracker:latest
    environment:
      - BACKEND_URL=http://backend:8080/api/instruments
      - FETCH_INTERVAL=180
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: on-failure
      labels:
        - "com.centurylinklabs.watchtower.enable=true"
    networks:
      - portfolio_network
    depends_on:
      - backend

  captcha-solver:
    image: ktenman/captcha-solver:latest
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      mode: replicated
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network
    depends_on:
      - app

  healthcheck:
    image: alpine:latest
    environment:
      - HEALTHCHECK_URL=${HEALTHCHECK_URL}
    command: |
      sh -c "
      apk add --no-cache curl;
      while true; do
        # Check all services with the portfolio stack
        if curl -fsS --retry 3 ${HEALTHCHECK_URL}; then
          echo 'Health check passed';
        else
          echo 'Health check failed';
        fi;
        sleep 300;
      done
      "
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
    networks:
      - portfolio_network

networks:
  portfolio_network:
    driver: overlay

volumes:
  postgres_data:
  redis_data:
  caddy_data:
  caddy_config:
